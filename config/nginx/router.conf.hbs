worker_processes {{nginx.workers}};

daemon off;

pid /tmp/api_umbrella_nginx_router.pid;

events {
  worker_connections 1024;
}

error_log stderr;

http {
  error_log {{log_dir}}/router_error.log;
  access_log {{log_dir}}/router_access.log combined buffer=32k flush=10s;

  client_body_temp_path /tmp/nginx_client_body_temp;
  proxy_temp_path /tmp/nginx_proxy_temp;
  fastcgi_temp_path /tmp/nginx_fastcgi_temp;
  uwsgi_temp_path /tmp/nginx_uwsgi_temp;
  scgi_temp_path /tmp/nginx_scgi_temp;
  server_tokens off;

  log_format api_umbrella_log '"$x_api_umbrella_uid","$router_name","$time_iso8601","$msec","$request_time","$upstream_response_time","$request_length","$bytes_sent","$status","$remote_addr","$request_method","$scheme","$http_host","$server_port","$request_uri","$http_user_agent","$http_referer","$http_x_api_key","$remote_user"';

  include ./mime.conf;

  {{#if test_env}}
  # Allow for these nginx-based rate limits to be disabled in the test
  # environment.
  map $http_x_disable_router_rate_limits $rate_limit_by {
    yes "";
    default $binary_remote_addr;
  }

  map $http_x_disable_router_connection_limits $connection_limit_by {
    yes "";
    default $binary_remote_addr;
  }
  {{else}}
  # Force the nginx-based rate limits to always be enabled in non-test
  # environments.
  map $http_x_disable_router_rate_limits $rate_limit_by {
    default $binary_remote_addr;
  }

  map $http_x_disable_router_connection_limits $connection_limit_by {
    default $binary_remote_addr;
  }
  {{/if}}

  # Limit the number of simultaneous connections per IP address.
  limit_conn_zone $connection_limit_by zone=api_umbrella_conn_addr_zone:{{router_global_rate_limits.ip_connections_size}};
  limit_conn_status {{apiSettings.error_data.over_rate_limit.status_code}};

  # Rate limits per IP address.
  #
  # In general, we want to rely on the more granular and configurable rate limits
  # provided by the API Umbrella Gatekeeper, so this limit should be higher than
  # the Gatekeeper's limits. This just provides an extra line of simple defense
  # against misbehaving clients from overloading the Gatekeeper.
  limit_req_zone $rate_limit_by zone=api_umbrella_req_addr_zone:{{router_global_rate_limits.ip_rate_size}} rate={{router_global_rate_limits.ip_rate}};
  limit_req_status {{apiSettings.error_data.over_rate_limit.status_code}};

  # Allow any sized uploads to backends.
  client_max_body_size 0;

  keepalive_timeout 30s;

  gzip on;
  gzip_comp_level 2;
  gzip_disable msie6;
  gzip_min_length 1000;
  gzip_proxied any;
  gzip_types application/atom+xml application/javascript application/json application/rss+xml application/x-javascript application/xml text/css text/csv text/javascript text/plain text/xml;
  gzip_vary on;

  upstream api_umbrella_web_backend {
    server 127.0.0.1:{{web.port}};
    keepalive 10;
  }

  upstream api_umbrella_static_site_backend {
    server 127.0.0.1:{{static_site.port}};
    keepalive 10;
  }

  upstream api_umbrella_gatekeeper_backends {
    # Set max_fails=0 to disable taking the servers out of rotation, even on
    # failures.
    #
    # This should maybe be revisited, since this isn't quite ideal, but this
    # fixes the default behavior that a bunch of backend timeouts can briefly
    # take all the servers out of rotation (and since we're not in control of
    # if an API backend times out, this doesn't seem ideal). The basic issue is
    # that "proxy_next_upstream" cannot exclude timeout errors from this: "The
    # cases of error, timeout and invalid_header are always considered
    # unsuccessful attempts, even if they are not specified in the directive."
    {{#each gatekeeper_hosts}}
    server {{.}} max_fails=0;
    {{/each}}
    keepalive 10;
  }

  # The main, front-facing public host server. This serves up both the APIs and
  # the web content.
  server {
    listen {{http_port}};
    listen {{https_port}} ssl;
    server_name api.vagrant localhost;

    ssl_certificate /etc/ssl/certs/vagrant.crt;
    ssl_certificate_key /etc/ssl/certs/vagrant.key;

    include ./frontend_defaults.conf;

    # Determine the SSL status when it's passed via X-Forwarded-Proto from the
    # SSL terminator.
    set $ssl_status "off";
    if ($server_port = {{https_port}}) {
      set $ssl_status "on";
    }

    if ($http_x_forwarded_proto = "https") {
      set $ssl_status "on";
    }

    # Match any required HTTPS-only pages.
    if ($uri ~ ^/(account|admin|admins|signup)(/|$)) {
      set $ssl_status "${ssl_status}_required";
    }

    # Force certain content to HTTPS-only.
    if ($ssl_status = "off_required") {
      rewrite ^ https://$server_name:{{https_port}}$request_uri? permanent;
    }

    # Route the docs and other static pages to the Rails web app. This may
    # change, so that's why we're treating it separately.
    location ~* ^/(|about|assets|community|contact|doc|docs|favicon\.ico|images|robots.txt|signup|static|__middleman|__rack)(/|$) {
      proxy_pass http://api_umbrella_static_site_backend;
    }

    # Route the dynamic portions of the site to the Rails web app.
    location ~* ^/(admin|admins|web-assets)(/|$) {
      proxy_pass http://api_umbrella_web_backend;
    }

    # Route all other requests as APIs going through the API Umbrella Gatekeeper.
    location / {
      include ./frontend_proxy_header_defaults.conf;
      include ./gatekeeper.conf;
    }
  }

  # Secondary hosts. These are other hosts we're handling only API traffic for,
  # but don't want to show web page content for.
  server {
    listen {{http_port}} default_server;
    #listen {{https_port}} ssl default_server;
    server_name _;

    include ./frontend_defaults.conf;

    # Route all other requests as APIs going through the API Umbrella Gatekeeper.
    location / {
      include ./frontend_proxy_header_defaults.conf;
      include ./gatekeeper.conf;
    }
  }

  {{#unless development_env}}
  server {
    listen {{static_site.port}};
    server_name _;

    root /vagrant/workspace/static-site/build;
  }
  {{/unless}}

  include ./api_backends.conf;

  map $http_accept_encoding $normalized_accept_encoding {
    "~(^|,) *gzip *; *q=0[\.0]* *($|,)" "";
    "~(^|,) *gzip *($|,|;)" gzip;
    default "";
  }

  server {
    listen {{router.api_backends.port}};
    server_name _;

    set $x_api_umbrella_uid $http_x_api_umbrella_uid;
    set $router_name "api_router";
    access_log {{log_dir}}/router.log api_umbrella_log buffer=32k flush=10s;

    # Enable keep alive connections to the backend servers.
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    keepalive_timeout 10s;

    proxy_set_header Host $host;
    proxy_set_header X-Api-Umbrella-UID "";
    proxy_set_header X-Api-Umbrella-Backend-Scheme "";
    proxy_set_header X-Api-Umbrella-Backend-Id "";

    # Only retry backends in the event of connection errors (and not also
    # connection timeouts as is the default). This prevents slow backend timeouts
    # triggering multiple requests if multiple backends are defined.
    proxy_next_upstream error;

    # Don't buffer proxied requests to allow for streaming APIs.
    proxy_buffering off;

    # If the backend only returns gzipped responses, decompress them as
    # appropriate to meet the Accept headers of the current client.
    gunzip on;

    location / {
      proxy_pass $http_x_api_umbrella_backend_scheme://api_umbrella_${http_x_api_umbrella_backend_id}_backend;
    }
  }
}
