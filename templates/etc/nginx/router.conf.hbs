worker_processes {{nginx.workers}};

daemon off;

{{#if user}}
user {{user}} {{group}};
{{/if}}

pid {{run_dir}}/router-nginx.pid;

events {
  worker_connections {{nginx.worker_connections}};
}

error_log stderr;

http {
  error_log {{log_dir}}/router-error.log;
  access_log {{log_dir}}/router-access.log combined buffer=32k flush=10s;

  client_body_temp_path {{tmp_dir}}/router-nginx-client_body_temp;
  proxy_temp_path {{tmp_dir}}/router-nginx-proxy_temp;
  fastcgi_temp_path {{tmp_dir}}/router-nginx-fastcgi_temp;
  uwsgi_temp_path {{tmp_dir}}/router-nginx-uwsgi_temp;
  scgi_temp_path {{tmp_dir}}/router-nginx-scgi_temp;
  server_tokens off;

  resolver 127.0.0.1:{{dnsmasq.port}};
  resolver_timeout 12s;

  # Log format for gathering the primary analytics.
  #
  # Note: This is manually constructed JSON to make dealing with it more sane
  # than a bunch of unnamed columns. nginx will escape quotes in values, so
  # this is safe, but you have to do manually deal with those escape sequences
  # before you can actually parse as JSON. See router_log_listener's handling
  # for more details.
  log_format api_umbrella_initial_router_log '{'
    '"id":"$x_api_umbrella_request_id",'
    '"source":"$router_name",'
    '"req_accept":"$http_accept",'
    '"req_accept_encoding":"$http_accept_encoding",'
    '"req_api_key_header":"$http_x_api_key",'
    '"req_api_key_query":"$arg_api_key",'
    '"req_at_msec":"$msec",'
    '"req_basic_auth_username":"$remote_user",'
    '"req_connection":"$http_connection",'
    '"req_content_type":"$http_content_type",'
    '"req_host":"$http_host",'
    '"req_ip":"$remote_addr",'
    '"req_method":"$request_method",'
    '"req_origin":"$http_origin",'
    '"req_port":"$real_port",'
    '"req_referer":"$http_referer",'
    '"req_scheme":"$real_scheme",'
    '"req_size":"$request_length",'
    '"req_uri":"$request_uri",'
    '"req_user_agent":"$http_user_agent",'
    '"res_age":"$sent_http_age",'
    '"res_content_encoding":"$sent_http_content_encoding",'
    '"res_content_length":"$sent_http_content_length",'
    '"res_content_type":"$sent_http_content_type",'
    '"res_server":"$upstream_http_server",'
    '"res_size":"$bytes_sent",'
    '"res_status":"$status",'
    '"res_time":"$request_time",'
    '"res_time_backend":"$upstream_response_time",'
    '"res_transfer_encoding":"$sent_http_transfer_encoding",'
    '"res_x_cache":"$sent_http_x_cache",'

    # These fields aren't technically used for our analytics gathering, but are
    # useful to have in files for grepping/debugging.
    '"req_at":"$time_iso8601"'
  '}';

  # Log format for gathering timer analytics from the backend router.
  log_format api_umbrella_api_backend_router_log '{'
    '"id":"$x_api_umbrella_request_id",'
    '"source":"$router_name",'
    '"res_time":"$request_time",'
    '"res_time_backend":"$upstream_response_time",'

    # These fields aren't technically used for our analytics gathering, but are
    # useful to have in files for grepping/debugging.
    '"req_at":"$time_iso8601",'
    '"req_host":"$http_host",'
    '"req_uri":"$request_uri",'
    '"res_status":"$status",'
    '"res_x_cache":"$sent_http_x_cache"'
  '}';

  include ./mime.conf;
  include ./realip.conf;

  geo $banned_ip {
    default 0;
    {{#each ban.ips}}
    {{.}} 1;
    {{/each}}
  }

  map $http_user_agent $banned_user_agent {
    default 0;
    {{#each ban.user_agents}}
    "{{.}}" 1;
    {{/each}}
  }

  {{#if test_env}}
  # Allow for these nginx-based rate limits to be disabled in the test
  # environment.
  map $http_x_disable_router_rate_limits $rate_limit_by {
    yes "";
    default $binary_remote_addr;
  }

  map $http_x_disable_router_connection_limits $connection_limit_by {
    yes "";
    default $binary_remote_addr;
  }
  {{else}}
  # Force the nginx-based rate limits to always be enabled in non-test
  # environments.
  map $http_x_disable_router_rate_limits $rate_limit_by {
    default $binary_remote_addr;
  }

  map $http_x_disable_router_connection_limits $connection_limit_by {
    default $binary_remote_addr;
  }
  {{/if}}

  # Limit the number of simultaneous connections per IP address.
  limit_conn_zone $connection_limit_by zone=api_umbrella_conn_addr_zone:{{router.global_rate_limits.ip_connections_size}};
  limit_conn_status {{apiSettings.error_data.over_rate_limit.status_code}};

  # Rate limits per IP address.
  #
  # In general, we want to rely on the more granular and configurable rate limits
  # provided by the API Umbrella Gatekeeper, so this limit should be higher than
  # the Gatekeeper's limits. This just provides an extra line of simple defense
  # against misbehaving clients from overloading the Gatekeeper.
  limit_req_zone $rate_limit_by zone=api_umbrella_req_addr_zone:{{router.global_rate_limits.ip_rate_size}} rate={{router.global_rate_limits.ip_rate}};
  limit_req_status {{apiSettings.error_data.over_rate_limit.status_code}};

  # Allow any sized uploads to backends.
  client_max_body_size 0;

  keepalive_timeout 30s;

  gzip on;
  gzip_comp_level 2;
  gzip_disable msie6;
  gzip_min_length 1000;
  gzip_proxied any;
  gzip_types application/atom+xml application/javascript application/json application/rss+xml application/x-javascript application/xml text/css text/csv text/javascript text/plain text/xml;
  gzip_vary on;

  upstream api_umbrella_web_backend {
    server {{web.host}}:{{web.port}};
    keepalive 10;
  }

  upstream api_umbrella_static_site_backend {
    server {{static_site.host}}:{{static_site.port}};
    keepalive 10;
  }

  upstream api_umbrella_gatekeeper_backends {
    # Set max_fails=0 to disable taking the servers out of rotation, even on
    # failures.
    #
    # This should maybe be revisited, since this isn't quite ideal, but this
    # fixes the default behavior that a bunch of backend timeouts can briefly
    # take all the servers out of rotation (and since we're not in control of
    # if an API backend times out, this doesn't seem ideal). The basic issue is
    # that "proxy_next_upstream" cannot exclude timeout errors from this: "The
    # cases of error, timeout and invalid_header are always considered
    # unsuccessful attempts, even if they are not specified in the directive."
    {{#each gatekeeper_hosts}}
    server {{host}} max_fails=0;
    {{/each}}
    keepalive 10;
  }

  {{#unless development_env}}
  server {
    listen {{static_site.port}};
    #listen [::]:{{static_site.port}};
    server_name _;
    port_in_redirect off;

    root {{static_site.build_dir}};
  }
  {{/unless}}

  include ./frontend_hosts.conf;
  include ./backends.conf;

  map $http_accept_encoding $normalized_accept_encoding {
    "~(^|,) *gzip *; *q=0[\.0]* *($|,)" "";
    "~(^|,) *gzip *($|,|;)" gzip;
    default "";
  }

  server {
    listen {{router.api_backends.port}};
    #listen [::]:{{router.api_backends.port}};
    server_name _;

    set $x_api_umbrella_request_id $http_x_api_umbrella_request_id;
    set $router_name "api_backend_router";
    access_log {{log_dir}}/router.log api_umbrella_api_backend_router_log buffer=32k flush=10s;
    access_log syslog:server=127.0.0.1:{{router.log_listener.port}} api_umbrella_api_backend_router_log;

    # Enable keep alive connections to the backend servers.
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    proxy_set_header Host $host;
    proxy_set_header X-Api-Umbrella-Backend-Scheme "";
    proxy_set_header X-Api-Umbrella-Backend-Id "";

    # Only retry backends in the event of connection errors (and not also
    # connection timeouts as is the default). This prevents slow backend timeouts
    # triggering multiple requests if multiple backends are defined.
    proxy_next_upstream error;

    # Don't buffer proxied requests to allow for streaming APIs.
    proxy_buffering off;

    # If the backend only returns gzipped responses, decompress them as
    # appropriate to meet the Accept headers of the current client.
    gunzip on;

    location / {
      proxy_pass $http_x_api_umbrella_backend_scheme://api_umbrella_${http_x_api_umbrella_backend_id}_backend;
    }
  }
}
